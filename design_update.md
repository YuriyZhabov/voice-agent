# Design Document Review: Voice Agent Platform
## –ê–Ω–∞–ª–∏–∑, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ —É–ª—É—á—à–µ–Ω–∏—è

---

## üìã EXECUTIVE SUMMARY

Design document —Ö–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω –∏ –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã —Å–∏—Å—Ç–µ–º—ã. –û–¥–Ω–∞–∫–æ –Ω–∞–π–¥–µ–Ω—ã **7 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤** –∏ **15 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π** –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è production-ready —Å—Ç–∞—Ç—É—Å–∞.

**–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: 7/10** ‚úÖ –•–æ—Ä–æ—à–∏–π —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç, –Ω—É–∂–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è

---

## üîç –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–ï–õ–´

### 1. ‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ SLA –∏ Performance Requirements

**–ü—Ä–æ–±–ª–µ–º–∞**: –ù–µ—Ç —á–µ—Ç–∫–∏—Ö SLA –¥–ª—è production:
- –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –¥–æ–ø—É—Å—Ç–∏–º–∞—è error rate
- –ù–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è P99 latency
- –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ availability

**–†–µ—à–µ–Ω–∏–µ**:
```yaml
SLAs:
  Availability:
    - Target: 99.9% uptime
    - Measured: Monthly (31 –¥–Ω–µ–π)
    - Excluded: Planned maintenance (4 —á–∞—Å–∞/–º–µ—Å—è—Ü max)
  
  Call Processing:
    - P50 (median) latency: <100ms (ASR ‚Üí Agent response)
    - P95 latency: <200ms
    - P99 latency: <300ms
    - Error rate: <0.5% (failed calls / total calls)
  
  Billing:
    - Payment webhook processing: <5 seconds
    - Balance update accuracy: 100%
    - Transaction consistency: No duplicates
  
  LLM Response:
    - Time to first token: <500ms
    - Fallback activation time: <2 seconds
    - Timeout: 30 seconds max
```

---

### 2. ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ËæπÁïå —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ (Edge Cases)

**–ü—Ä–æ–±–ª–µ–º—ã**:

a) **–û–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–≤–æ–Ω–∫–∏ –Ω–∞ –æ–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞**
```
–°—Ü–µ–Ω–∞—Ä–∏–π: 10 –∑–≤–æ–Ω–∫–æ–≤ ‚Üí 1 –∞–≥–µ–Ω—Ç (max_concurrent_calls = 10)
–¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: –ú–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ race condition
–†–µ—à–µ–Ω–∏–µ: –ù—É–∂–µ–Ω queue —Å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π
```

b) **–ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –≤–æ –≤—Ä–µ–º—è TTS**
```
–°—Ü–µ–Ω–∞—Ä–∏–π: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç, –ø–æ–∫–∞ –∞–≥–µ–Ω—Ç –æ–∑–≤—É—á–∏–≤–∞–µ—Ç
–¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: –ù–µ –æ–ø–∏—Å–∞–Ω–æ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
–†–µ—à–µ–Ω–∏–µ: –ù—É–∂–Ω–∞ –ª–æ–≥–∏–∫–∞ interrupt detection + cancellation token
```

c) **Network disconnection during call**
```
–°—Ü–µ–Ω–∞—Ä–∏–π: LiveKit room –ø–æ—Ç–µ—Ä—è–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
–¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: –ù–µ—Ç recovery –º–µ—Ö–∞–Ω–∏–∑–º–∞
–†–µ—à–µ–Ω–∏–µ: Exponential backoff + auto-reconnect —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
```

**–î–æ–±–∞–≤–∏—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç**:
```typescript
// Edge case handling
interface CallResilience {
  maxConcurrentPerAgent: number;           // 10
  interruptDetectionMs: number;             // 100ms window
  networkReconnectBackoff: BackoffConfig;   // exp: 1s, 2s, 4s, 8s (max)
  contextPreservationTtl: number;           // 5 –º–∏–Ω—É—Ç
}

// Interrupt handling
interface InterruptDetection {
  vadThreshold: number;                     // decibels for user speech
  agentTtsStoppable: boolean;               // true = –º–æ–∂–µ–º –ø—Ä–µ—Ä—ã–≤–∞—Ç—å
  interruptGracePeriod: number;             // 500ms - –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Å—Ä–∞–∑—É
}
```

---

### 3. ‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—èÂ§±Ë¥• LLM —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤

**–ü—Ä–æ–±–ª–µ–º–∞**: Fallback strategy —É–ø–æ–º—è–Ω—É—Ç–∞, –Ω–æ –Ω–µ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞

**–†–µ—à–µ–Ω–∏–µ - –î–µ—Ç–∞–ª—å–Ω—ã–π fallback flow**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            LLM FAILURE HANDLING (DETAILED)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

–°—Ü–µ–Ω–∞—Ä–∏–π 1: OpenAI rate limited
‚îú‚îÄ Detection: 429 status + remaining quota = 0
‚îú‚îÄ Action: Log warning, switch to Claude immediately
‚îú‚îÄ Fallback chain: Claude ‚Üí Llama (edge GPU)
‚îî‚îÄ User experience: No latency impact (<100ms switching)

–°—Ü–µ–Ω–∞—Ä–∏–π 2: OpenAI returns invalid JSON (tool_calls parse error)
‚îú‚îÄ Detection: JSON parse error
‚îú‚îÄ Action: Retry with same prompt (max 2 times)
‚îú‚îÄ Fallback: Ask user to repeat, clear context
‚îî‚îÄ Recovery: Continue conversation without tools

–°—Ü–µ–Ω–∞—Ä–∏–π 3: OpenAI timeout (>30 seconds)
‚îú‚îÄ Detection: Promise timeout
‚îú‚îÄ Action: Cancel request, try Claude
‚îú‚îÄ User notification: "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å..."
‚îî‚îÄ Max total time: 60 seconds, then close call

–°—Ü–µ–Ω–∞—Ä–∏–π 4: All LLMs unavailable
‚îú‚îÄ Action: Use pre-trained local Llama 2
‚îú‚îÄ Capabilities: Reduced (no tool calls, simpler responses)
‚îú‚îÄ User notification: "–í—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è. –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ–º–æ—á—å."
‚îî‚îÄ Graceful degradation: Better than silence
```

**–î–æ–±–∞–≤–∏—Ç—å –∫–æ–¥ –≤ Agent Orchestration**:
```python
class LLMRouter:
    async def get_response(self, prompt: str, attempt: int = 0) -> str:
        """
        Multi-tier fallback for LLM with circuit breaker
        """
        models = [
            ("openai", self.openai_client, timeout=30),
            ("claude", self.claude_client, timeout=30),
            ("llama_edge", self.llama_client, timeout=15),  # –ª–æ–∫–∞–ª—å–Ω–∞—è
        ]
        
        for model_name, client, timeout in models[attempt:]:
            try:
                response = await asyncio.wait_for(
                    client.chat(prompt),
                    timeout=timeout
                )
                logger.info(f"‚úÖ LLM success: {model_name}")
                return response
            
            except asyncio.TimeoutError:
                logger.warning(f"‚è± {model_name} timeout")
                if attempt < len(models) - 1:
                    return await self.get_response(prompt, attempt + 1)
            
            except Exception as e:
                logger.error(f"‚ùå {model_name} error: {e}")
                if attempt < len(models) - 1:
                    return await self.get_response(prompt, attempt + 1)
        
        # All LLMs failed - use fallback
        return self.get_fallback_response(prompt)
```

---

### 4. ‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ Streaming Pipeline

**–ü—Ä–æ–±–ª–µ–º–∞**: –î–æ–∫—É–º–µ–Ω—Ç –≥–æ–≤–æ—Ä–∏—Ç –æ <300ms latency, –Ω–æ –Ω–µ –æ–±—ä—è—Å–Ω—è–µ—Ç HOW

**–†–µ—à–µ–Ω–∏–µ - –î–µ—Ç–∞–ª—å–Ω–∞—è timeline**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         STREAMING CALL LATENCY BREAKDOWN                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                            ‚îÇ
‚îÇ 1. User speaks (2 seconds of speech)                       ‚îÇ
‚îÇ    ‚îú‚îÄ Word 1 sent to Deepgram at 0.5s                     ‚îÇ
‚îÇ    ‚îî‚îÄ Deepgram streaming result at 0.7s                   ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ 2. ASR ‚Üí Agent processing (15-50ms)                        ‚îÇ
‚îÇ    ‚îú‚îÄ Extract text from Deepgram: 5ms                     ‚îÇ
‚îÇ    ‚îú‚îÄ Load context from Redis: 10ms                       ‚îÇ
‚îÇ    ‚îî‚îÄ Validate with VAD: 5ms                              ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ 3. LLM inference (200-500ms depending on model)           ‚îÇ
‚îÇ    ‚îú‚îÄ Send to OpenAI: 50ms network                        ‚îÇ
‚îÇ    ‚îú‚îÄ LLM processing: 150-400ms                           ‚îÇ
‚îÇ    ‚îú‚îÄ Receive first token: 50ms                           ‚îÇ
‚îÇ    ‚îî‚îÄ Total: 250-500ms ‚Üê CRITICAL PATH                    ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ 4. Agent streaming response construction                  ‚îÇ
‚îÇ    ‚îú‚îÄ Stream tokens to TTS immediately: 0ms (parallel)   ‚îÇ
‚îÇ    ‚îú‚îÄ TTS synthesis (ElevenLabs): 100-200ms              ‚îÇ
‚îÇ    ‚îú‚îÄ First audio chunk to user: 50ms                     ‚îÇ
‚îÇ    ‚îî‚îÄ Total: 150-250ms (PARALLEL with LLM)               ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ 5. User hears response                                    ‚îÇ
‚îÇ    ‚îú‚îÄ Network latency: 10-30ms                            ‚îÇ
‚îÇ    ‚îî‚îÄ Audio playback start: 0ms (async)                   ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ TOTAL END-TO-END: 400-700ms                               ‚îÇ
‚îÇ But user hears first audio in 500-600ms (acceptable)      ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ KEY OPTIMIZATION: Parallelize LLM + TTS                   ‚îÇ
‚îÇ - LLM generates first token at 250ms                      ‚îÇ
‚îÇ - Start TTS with "–°–µ–π—á–∞—Å..." at 260ms                     ‚îÇ
‚îÇ - User hears at 400ms while LLM still generating          ‚îÇ
‚îÇ - Natural feel: user never waits in silence               ‚îÇ
‚îÇ                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Code Example: Parallel LLM + TTS Streaming
```

```python
async def stream_agent_response(self, user_text: str):
    """
    Stream LLM tokens DIRECTLY to TTS without waiting for full response
    This is KEY to achieving <300ms perceived latency
    """
    # 1. Get LLM stream
    llm_stream = self.llm_client.stream_tokens(user_text)
    
    # 2. Create TTS buffer
    tts_queue = asyncio.Queue(maxsize=10)
    
    # 3. Task 1: Consume LLM tokens ‚Üí accumulate ‚Üí send to TTS
    async def feed_tts():
        text_buffer = ""
        async for token in llm_stream:
            text_buffer += token
            # Send sentence-length chunks to TTS
            if any(text_buffer.endswith(punct) for punct in '.!?'):
                await tts_queue.put(text_buffer.strip())
                text_buffer = ""
            # Also send periodic chunks to avoid long waits
            elif len(text_buffer) > 40:
                await tts_queue.put(text_buffer)
                text_buffer = ""
    
    # 4. Task 2: Consume TTS queue ‚Üí synthesize ‚Üí stream to user
    async def stream_audio():
        while True:
            try:
                text_chunk = tts_queue.get_nowait()
                async for audio_chunk in self.tts.stream(text_chunk):
                    await self.livekit.publish_audio(audio_chunk)
            except asyncio.QueueEmpty:
                await asyncio.sleep(0.05)  # Small delay to batch
    
    # 5. Run both in parallel
    await asyncio.gather(feed_tts(), stream_audio())
```

---

### 5. ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ Billing Race Conditions

**–ü—Ä–æ–±–ª–µ–º–∞**: –ß—Ç–æ –µ—Å–ª–∏ –∑–≤–æ–Ω–æ–∫ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è –∏ –ø–ª–∞—Ç–µ–∂ –ø–æ—Å—Ç—É–ø–∞–µ—Ç?

```
Scenario: User.balance = 100 kopecks
‚îú‚îÄ Event 1: call.ended (duration 1 min = 1000 kopecks needed)
‚îú‚îÄ Event 2: payment.succeeded (balance + 5000 kopecks)
‚îú‚îÄ Question: –ö–∞–∫–æ–π –ø–æ—Ä—è–¥–æ–∫? –ë–∞–ª–∞–Ω—Å -900 –∏–ª–∏ +4000?
‚îî‚îÄ Current doc: –ú–æ–ª—á–∏—Ç
```

**–†–µ—à–µ–Ω–∏–µ - Transactional consistency**:
```sql
-- Current: Denormalized table (WRONG for race conditions)
CREATE TABLE balances (
    org_id UUID PRIMARY KEY,
    balance_kopecks NUMERIC,
    updated_at TIMESTAMP
);

-- Better: Event-sourcing approach with transaction log
CREATE TABLE billing_events (
    id BIGSERIAL PRIMARY KEY,
    org_id UUID NOT NULL,
    event_type VARCHAR(50),  -- 'call_ended', 'payment_received'
    amount_kopecks NUMERIC,
    idempotency_key VARCHAR(255) UNIQUE,  -- Prevent duplicates
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE balances_computed (
    org_id UUID PRIMARY KEY,
    balance_kopecks NUMERIC,
    last_event_id BIGINT,  -- Point-in-time snapshot
    updated_at TIMESTAMP
);

-- Guarantee: Idempotency
-- If same payment_id comes twice, only apply once
CREATE UNIQUE INDEX billing_events_idempotency 
    ON billing_events(org_id, idempotency_key);

-- Guarantee: Serializability
-- Process events in order, recalculate balance deterministically
```

**–ö–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π**:
```python
async def apply_billing_event(org_id: str, event: BillingEvent):
    """
    Idempotent billing event application
    –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç: –∫–∞–∂–¥–æ–µ —Å–æ–±—ã—Ç–∏–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω —Ä–∞–∑
    """
    idempotency_key = f"{event.type}:{event.external_id}"
    
    # 1. Check if already applied
    existing = await db.query("""
        SELECT id FROM billing_events 
        WHERE org_id = $1 AND idempotency_key = $2
    """, org_id, idempotency_key)
    
    if existing:
        logger.info(f"Event {idempotency_key} already applied")
        return
    
    # 2. Insert event with idempotency check (UNIQUE constraint)
    try:
        await db.query("""
            INSERT INTO billing_events 
            (org_id, event_type, amount_kopecks, idempotency_key)
            VALUES ($1, $2, $3, $4)
        """, org_id, event.type, event.amount, idempotency_key)
    except IntegrityError:
        # Lost race - another process inserted it first
        logger.warning(f"Lost race for {idempotency_key}")
        return
    
    # 3. Recalculate balance from all events (deterministic)
    balance = await db.query_scalar("""
        SELECT COALESCE(SUM(CASE 
            WHEN event_type = 'payment_received' THEN amount_kopecks
            WHEN event_type = 'call_ended' THEN -amount_kopecks
            ELSE 0
        END), 0)
        FROM billing_events
        WHERE org_id = $1
    """, org_id)
    
    # 4. Update denormalized table
    await db.query("""
        UPDATE balances SET balance_kopecks = $1, updated_at = NOW()
        WHERE org_id = $2
    """, balance, org_id)
    
    logger.info(f"‚úÖ Applied event {idempotency_key}, balance = {balance}")
```

---

### 6. ‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ Circuit Breaker –¥–ª—è SIP trunk

**–ü—Ä–æ–±–ª–µ–º–∞**: MTS Exolve –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Üí –Ω–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏

```
Current flow:
‚îú‚îÄ Incoming call ‚Üí SIP INVITE
‚îú‚îÄ [MTS Exolve down?]
‚îú‚îÄ LiveKit room creation fails
‚îî‚îÄ Caller hears error

Better flow (with circuit breaker):
‚îú‚îÄ Incoming call ‚Üí SIP INVITE
‚îú‚îÄ MTS Exolve returns error ‚Üí increment failure counter
‚îú‚îÄ Failures > threshold ‚Üí open circuit
‚îú‚îÄ Return busy signal gracefully
‚îú‚îÄ Health check every 30 seconds
‚îî‚îÄ Auto-recover when healthy
```

**–î–æ–±–∞–≤–∏—Ç—å**:
```typescript
interface SIPCircuitBreaker {
  failureThreshold: number;           // 5 failed calls
  successThreshold: number;            // 3 successful calls
  timeout: number;                     // 30 seconds
  states: {
    closed: string;                    // Normal operation
    open: string;                      // Return busy signal
    halfOpen: string;                  // Testing if recovered
  };
}

// Health check
async function sipHealthCheck(): Promise<boolean> {
  try {
    const response = await pjsua2.register({
      uri: "sip:health-check@exolve.mts.ru",
      timeout: 5000
    });
    return response.status === 200;
  } catch (e) {
    logger.error(`SIP health check failed: ${e.message}`);
    return false;
  }
}
```

---

### 7. ‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è Graceful Shutdown

**–ü—Ä–æ–±–ª–µ–º–∞**: –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ ‚Üí –≤—Å–µ –∑–≤–æ–Ω–∫–∏ —Ç–µ—Ä—è—é—Ç—Å—è

```
Current: Kill process ‚Üí active calls drop
Better: 
‚îú‚îÄ Stop accepting new calls
‚îú‚îÄ Wait for existing calls to finish (max 10 min)
‚îú‚îÄ Publish call.shutdown_initiated event
‚îî‚îÄ Clean exit
```

**–î–æ–±–∞–≤–∏—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç**:
```typescript
interface GracefulShutdownConfig {
  maxWaitTimeSeconds: number;         // 600 (10 minutes)
  notifyInterval: number;              // 60 seconds (log remaining)
  finalCallTimeout: number;            // 300 seconds force kill
}

async function gracefulShutdown() {
  logger.info("üõë Graceful shutdown initiated");
  
  // 1. Stop accepting new calls
  expressApp.use((req, res) => {
    res.status(503).json({ error: "Server shutting down" });
  });
  
  // 2. Notify all active calls
  const activeCalls = Array.from(callService.activeCalls.values());
  logger.info(`üìû Notifying ${activeCalls.length} active calls`);
  
  for (const call of activeCalls) {
    await callService.publishEvent("call.shutdown_initiated", {
      call_id: call.callId,
      gracePeriodSeconds: 600
    });
  }
  
  // 3. Wait for calls to end (with timeout)
  const shutdownTimer = setTimeout(async () => {
    logger.warn("‚ö†Ô∏è Force killing remaining calls");
    for (const call of callService.activeCalls.values()) {
      await callService.handleCallEnded(call.callId, "forced_shutdown");
    }
  }, 600000);  // 10 minutes
  
  // 4. Monitor and exit when all calls done
  while (callService.activeCalls.size > 0) {
    logger.info(`‚è≥ Waiting for ${callService.activeCalls.size} calls to finish`);
    await sleep(10000);  // Check every 10 seconds
  }
  
  clearTimeout(shutdownTimer);
  logger.info("‚úÖ All calls completed, exiting gracefully");
  process.exit(0);
}
```

---

## üí° 15 –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø

### Tier 1: CRITICAL (Implement before production)

#### 1. **–î–æ–±–∞–≤–∏—Ç—å Monitoring & Observability strategy**

```yaml
Metrics to track:
  Call metrics:
    - call_duration_seconds (histogram)
    - call_error_rate (counter)
    - concurrent_calls_active (gauge)
    - call_wait_time_before_agent (histogram)
    - agent_response_latency_ms (histogram, 50/95/99 percentiles)
  
  LLM metrics:
    - llm_inference_time_ms (histogram)
    - llm_tokens_generated (counter)
    - llm_fallback_activations (counter)
    - llm_error_rate (gauge)
  
  Billing metrics:
    - transaction_amount_kopecks (histogram)
    - payment_webhook_latency_ms (histogram)
    - balance_updates_per_minute (gauge)
  
  System metrics:
    - kafka_lag_by_topic (gauge)
    - database_query_latency_ms (histogram)
    - redis_cache_hit_rate (gauge)

Dashboards needed:
  - Real-time call health (P50/P95/P99 latency)
  - Agent performance (success rate, sentiment)
  - Billing accuracy (transactions vs real)
  - System health (error rates, latency)

Alerting:
  - Error rate > 1%
  - P99 latency > 500ms
  - Payment webhook latency > 10s
  - Kafka lag > 5 minutes
  - Database connections > 80% pool
```

#### 2. **–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å Load Testing strategy**

```
Test scenarios:
‚îú‚îÄ Concurrent calls: 100, 500, 1000, 5000
‚îú‚îÄ LLM latency: Inject 200ms, 500ms, 2s delays
‚îú‚îÄ Tool execution: 10 parallel tools, 5 timeout
‚îú‚îÄ Payment processing: 1000 webhook events/min
‚îú‚îÄ Database: Query latency under load
‚îî‚îÄ Network: Packet loss 1%, 5%, 10%

Tools: k6, JMeter for call simulation
```

#### 3. **–î–æ–±–∞–≤–∏—Ç—å Disaster Recovery Plan**

```
RTO (Recovery Time Objective): 1 hour
RPO (Recovery Point Objective): 5 minutes

Backup strategy:
- PostgreSQL: WAL archiving to S3 + daily snapshots
- Kafka: Replication factor 3
- S3: Versioning enabled, cross-region replication
- Configuration: Git + encrypted secrets in Vault

Recovery procedures:
- Point-in-time restore from WAL (90 days)
- Kafka rebalancing (automatic)
- S3 version restore (via CloudFront invalidation)
```

#### 4. **–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å Quota & Rate Limiting**

```
Per-organization limits:
  - max_agents: 50
  - max_concurrent_calls: 100
  - max_tools_per_agent: 20
  - monthly_call_minutes: Based on plan
  - api_requests_per_minute: 1000

Per-user limits:
  - api_key_requests_per_minute: 200
  - concurrent_dashboard_sessions: 5
  - webhook_push_errors: 10/hour before disable
```

#### 5. **–î–æ–±–∞–≤–∏—Ç—å Webhook Retry & DLQ strategy**

```python
# Current: agent.escalation_triggered, but no retry policy

class WebhookManager:
    async def send_webhook(self, org_id: str, event: dict):
        """
        Send webhook with exponential backoff + DLQ
        """
        webhook_config = await db.get_webhook(org_id)
        
        for attempt in range(5):  # 5 retries
            try:
                response = await http.post(
                    webhook_config.url,
                    json=event,
                    timeout=10,
                    headers={"X-Webhook-Attempt": str(attempt)}
                )
                
                if response.status == 200:
                    await db.webhook_log(org_id, event.id, "success")
                    return
                
                if response.status in [400, 401, 403, 404]:
                    # Don't retry client errors
                    await db.webhook_log(org_id, event.id, "permanent_error")
                    await send_to_dlq(event)
                    return
            
            except Exception as e:
                wait_time = 2 ** attempt  # 1s, 2s, 4s, 8s, 16s
                logger.warning(f"Webhook attempt {attempt} failed: {e}, retrying in {wait_time}s")
                await asyncio.sleep(wait_time)
        
        # All retries failed ‚Üí send to Dead Letter Queue
        logger.error(f"Webhook delivery failed after 5 attempts")
        await send_to_dlq(event)
```

---

### Tier 2: IMPORTANT (Implement in v1.1)

#### 6. **–î–æ–±–∞–≤–∏—Ç—å Intent Classification & Routing**

```python
# Current: Agent just processes user speech

class IntentClassifier:
    """
    Route call to specialized agent based on intent
    """
    async def classify(self, text: str) -> Intent:
        """
        Examples:
        - "—è —Ö–æ—á—É –ø–æ–ø–æ–ª–Ω–∏—Ç—å —Å—á–µ—Ç" ‚Üí billing_agent
        - "—É –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º–∞ —Å —É—Å–ª—É–≥–æ–π" ‚Üí support_agent
        - "–∫–∞–∫ –∏–∑–º–µ–Ω–∏—Ç—å —Ç–∞—Ä–∏—Ñ" ‚Üí sales_agent
        """
        # Use Claude for fast classification (not full OpenAI)
        intent = await self.claude.classify_intent(text)
        return intent

# Use in orchestrator
agent_config = await self.get_agent_by_intent(classified_intent)
```

#### 7. **–î–æ–±–∞–≤–∏—Ç—å Analytics for Call Quality**

```
Call quality metrics:
‚îú‚îÄ Speech recognition confidence (mean Deepgram confidence)
‚îú‚îÄ Turn-taking smoothness (gaps between user/agent)
‚îú‚îÄ Sentiment trajectory (positive ‚Üí negative = issue)
‚îú‚îÄ Tool success rate (succeeded tools / total tools called)
‚îú‚îÄ User interruption frequency (more = bad UX)
‚îú‚îÄ Call resolution rate (did agent solve problem?)
‚îî‚îÄ CSAT (Could add post-call survey)
```

#### 8. **–î–æ–±–∞–≤–∏—Ç—å Agent Performance Metrics**

```
Per-agent metrics:
‚îú‚îÄ Average call duration
‚îú‚îÄ Call completion rate (%)
‚îú‚îÄ Customer satisfaction (positive sentiment %)
‚îú‚îÄ First-call resolution rate
‚îú‚îÄ Error rate (failed tool calls %)
‚îú‚îÄ Average response time
‚îî‚îÄ Cost per call (billing_cost / calls)

Dashboard: Show trends, allow comparison, identify best performers
```

#### 9. **–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å Testing –¥–ª—è Correctness Properties**

```typescript
// Example property test for Property 23: Call cost calculation

import { fc } from 'fast-check';

/**
 * **Feature: voice-agent-platform, Property 23: Call cost calculation**
 * **Validates: Requirements 8.1**
 * 
 * For any call with duration in seconds and plan with rate per minute,
 * cost SHALL be calculated as: ceil(duration / 60) * rate
 */
describe('Billing Service', () => {
  it('should calculate call cost correctly (Property 23)', () => {
    fc.assert(
      fc.property(
        fc.integer({ min: 1, max: 3600 }),     // duration in seconds
        fc.integer({ min: 1, max: 100 }),      // rate per minute
        (durationSeconds, ratePerMinute) => {
          const cost = billingService.calculateCost(durationSeconds, ratePerMinute);
          const expectedMinutes = Math.ceil(durationSeconds / 60);
          const expectedCost = expectedMinutes * ratePerMinute * 100;  // in kopecks
          
          expect(cost).toBe(expectedCost);
        }
      ),
      { numRuns: 1000, verbose: true }
    );
  });
});
```

#### 10. **–î–æ–±–∞–≤–∏—Ç—å Segment Analytics Integration**

```typescript
// Track user behavior for product insights

class AnalyticsTracker {
  async trackCallStarted(call: Call) {
    segment.track({
      userId: call.organizationId,
      event: 'call_started',
      properties: {
        agentId: call.agentId,
        direction: call.direction,
        fromNumber: maskPhoneNumber(call.fromNumber),
        toNumber: maskPhoneNumber(call.toNumber)
      }
    });
  }
  
  async trackToolExecuted(tool: ToolResult) {
    segment.track({
      userId: context.organizationId,
      event: 'tool_executed',
      properties: {
        toolName: tool.tool_name,
        success: !tool.error,
        executionTimeMs: tool.execution_time_ms
      }
    });
  }
}

// Insights: Which tools are used most? Which agents are most efficient?
```

---

### Tier 3: NICE-TO-HAVE (Future improvements)

#### 11. **–î–æ–±–∞–≤–∏—Ç—å Custom LLM fine-tuning**

```
For organizations with specific domain (e.g., banking),
allow fine-tuning on their call transcripts
‚îî‚îÄ After 100 successful calls, suggest fine-tuning
‚îî‚îÄ Fine-tuned model: +20% accuracy improvement expected
‚îî‚îÄ Cost: $100-500 per fine-tuning
```

#### 12. **–î–æ–±–∞–≤–∏—Ç—å A/B Testing framework**

```
Run experiments:
‚îú‚îÄ Different system prompts
‚îú‚îÄ Different voices
‚îú‚îÄ Different greeting messages
‚îú‚îÄ Different tool sets
‚îî‚îÄ Measure: sentiment, resolution rate, cost per call
```

#### 13. **–î–æ–±–∞–≤–∏—Ç—å Voice Authentication**

```
Security feature:
‚îú‚îÄ Verify caller identity by voice
‚îú‚îÄ Block spoofed numbers
‚îú‚îÄ Detect fraud patterns
‚îî‚îÄ CNAM lookup integration
```

#### 14. **–î–æ–±–∞–≤–∏—Ç—å Sentiment-triggered Actions**

```
If sentiment turns negative during call:
‚îú‚îÄ Escalate to human agent
‚îú‚îÄ Offer live chat option
‚îú‚îÄ Change agent tone (more empathetic system prompt)
‚îú‚îÄ Add extra tools for problem resolution
‚îî‚îÄ Post-call follow-up
```

#### 15. **–î–æ–±–∞–≤–∏—Ç—å Cost Optimization**

```
Suggestions:
‚îú‚îÄ Use cheaper LLM (gpt-4o-mini vs gpt-4o)
‚îú‚îÄ Batch similar calls for TTS synthesis
‚îú‚îÄ Cache common responses
‚îú‚îÄ Use local Llama for simple queries
‚îî‚îÄ Monitor and alert on cost anomalies
```

---

## ‚úÖ –ò–¢–û–ì–û–í–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò

### –ü–µ—Ä–µ–¥ Production Release:

1. ‚úÖ **MUST FIX**:
   - [ ] Add SLA definitions (Section 1)
   - [ ] Add edge case handling (Section 2)
   - [ ] Detail fallback strategy (Section 3)
   - [ ] Document streaming pipeline timeline (Section 4)
   - [ ] Add billing transaction idempotency (Section 5)
   - [ ] Add SIP circuit breaker (Section 6)
   - [ ] Add graceful shutdown (Section 7)

2. ‚úÖ **STRONGLY RECOMMENDED**:
   - [ ] Monitoring & alerting strategy
   - [ ] Load testing plan
   - [ ] Disaster recovery procedure
   - [ ] Quota & rate limiting policy
   - [ ] Webhook retry & DLQ

3. ‚úÖ **ROADMAP (v1.1)**:
   - [ ] Intent classification
   - [ ] Advanced analytics
   - [ ] Agent performance metrics
   - [ ] Property-based testing
   - [ ] Segment integration

---

## üìä UPDATED DOCUMENT SCORING

| Category | Before | After | Notes |
|----------|--------|-------|-------|
| Architecture clarity | 8/10 | 9/10 | Added latency timeline |
| Error handling | 5/10 | 8/10 | Detailed fallback + edge cases |
| Completeness | 6/10 | 8/10 | SLA, monitoring, recovery |
| Producibility | 6/10 | 8/10 | Circuit breaker, graceful shutdown |
| Testability | 7/10 | 9/10 | Property tests documented |
| **OVERALL** | **6.4/10** | **8.4/10** | ‚úÖ Production-ready |

---

## üöÄ NEXT STEPS

1. **Integrate kritical feedback** (Section 1-7) into main doc
2. **Create separate** "Operations Guide" for Tier 1 items
3. **Add monitoring** configuration to DevOps repo
4. **Create checklist** for production launch
5. **Schedule review** before each release